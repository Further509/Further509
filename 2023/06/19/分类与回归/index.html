<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Yang Mingxin"><meta name="keywords" content="blog"><meta name="description" content="分类是一种典型的有监督学习问题分类一般分为以下两个阶段：  分类器训练：即通过训练样本的特征和标签来建立分类模型 分类预测：利用分类模型对没有分类标签的数据进行分类数据集划分为训练集和测试集 训练集训练分类器 测试集用于评估分类性能  决策树分类算法CLSCLS算法问题：       测试属性集的组成以及测试属性的先后对决策树的学习具有举足轻重的影响。 ID3**不纯度 (impurity)**："><meta property="og:type" content="article"><meta property="og:title" content="分类与回归"><meta property="og:url" content="https://furthur509.github.io/2023/06/19/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92/index.html"><meta property="og:site_name" content="Yang Mingxin&#39;s Blog"><meta property="og:description" content="分类是一种典型的有监督学习问题分类一般分为以下两个阶段：  分类器训练：即通过训练样本的特征和标签来建立分类模型 分类预测：利用分类模型对没有分类标签的数据进行分类数据集划分为训练集和测试集 训练集训练分类器 测试集用于评估分类性能  决策树分类算法CLSCLS算法问题：       测试属性集的组成以及测试属性的先后对决策树的学习具有举足轻重的影响。 ID3**不纯度 (impurity)**："><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://furthur509.github.io/img/shuju2.jpg"><meta property="article:published_time" content="2023-06-19T10:37:04.000Z"><meta property="article:modified_time" content="2023-06-23T14:55:53.435Z"><meta property="article:author" content="Yang Mingxin"><meta property="article:tag" content="数据科学导论"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://furthur509.github.io/img/shuju2.jpg"><meta name="referrer" content="no-referrer-when-downgrade"><title>分类与回归 - Yang Mingxin&#39;s Blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"furthur509.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:60,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Yang Mingxin&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/indexsecond.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="分类与回归"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-06-19 18:37" pubdate>2023年6月19日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 1.6k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 14 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">分类与回归</h1><p class="note note-info">本文最后更新于：2023年6月23日 晚上</p><div class="markdown-body"><p>分类是一种典型的有监督学习问题<br><strong>分类一般分为以下两个阶段：</strong></p><ol><li>分类器训练：即通过训练样本的特征和标签来建立分类模型</li><li>分类预测：利用分类模型对没有分类标签的数据进行分类<br><strong>数据集划分为训练集和测试集</strong></li><li>训练集训练分类器</li><li>测试集用于评估分类性能</li></ol><h1 id="决策树分类算法"><a href="#决策树分类算法" class="headerlink" title="决策树分类算法"></a>决策树分类算法</h1><h2 id="CLS"><a href="#CLS" class="headerlink" title="CLS"></a>CLS</h2><p>CLS算法问题：<br>测试属性集的组成以及测试属性的先后对决策树的学习具有举足轻重的影响。</p><h2 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h2><p>**不纯度 (impurity)**：<br>表示落在当前节点的样本类别分布的均衡程度，节点分裂后，节点不纯度应该更低，选择特征及对应分割点，使得分裂前后的不纯度(impurity)下降最大。<br>节点不纯度的度量</p><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><h4 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h4><h3 id="Gini指数"><a href="#Gini指数" class="headerlink" title="Gini指数"></a>Gini指数</h3><h3 id="误分率"><a href="#误分率" class="headerlink" title="误分率"></a>误分率</h3><p>ID3算法存在的问题：<br>倾向于分裂成很多的小节点（节点的样本数较小），容易造成过拟合</p><h2 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h2><h3 id="信息增益率"><a href="#信息增益率" class="headerlink" title="信息增益率"></a>信息增益率</h3><h2 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h2><h1 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h1><p>0概率处理：<br>加1平滑，使用加1的方法估计没有出现过现象的概率，以保证概率不会出现0<br>优缺点分析：</p><h1 id="K近邻"><a href="#K近邻" class="headerlink" title="K近邻"></a>K近邻</h1><h1 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h1><h2 id="一元线性回归"><a href="#一元线性回归" class="headerlink" title="一元线性回归"></a>一元线性回归</h2><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><h2 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h2><p><strong>多项式回归的优点</strong>：可以通过增加 x 的高次项对实测点进行逼近，直至满意为止。<br>多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，因为任一函数都可以分段用多项式来逼近。因此，在通常的实际问题中，不论依变量与其他自变量的关系如何，我们总可以用多项式回归来进行分析。</p><h2 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h2><h3 id="减少特征数量"><a href="#减少特征数量" class="headerlink" title="减少特征数量"></a>减少特征数量</h3><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><h4 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h4><h4 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h4><h4 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h4><h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><p>最大化边界<br>线性不可分——升维<br>核函数</p><h1 id="关联规则挖掘"><a href="#关联规则挖掘" class="headerlink" title="关联规则挖掘"></a>关联规则挖掘</h1><p>支持度，置信度（条件概率</p><p><strong>事务</strong>：每一条购物信息可以被定义为一个事务；<br><strong>项</strong>：购物信息中的一项物品被定义为项；<br><strong>项集</strong>：包含零个项或多个项的集合被称为项集，含有k个项的项集称为k项集；<br><strong>关联规则</strong>就可以表示为形如“A&#x3D;&gt;B” 的蕴涵式，其中A，B均为非空项集，且A∩B&#x3D; ∅。<br>支持度大于预定义的最小支持度阈值的项集称为<strong>频繁项集</strong>。<br>有了频繁项集的定义，可以把从数据集中挖掘强关联规则的过程分为两步：<br>第一步：需要找出满足最小支持度阈值的项集，即频繁项集；<br>第二步：根据最小置信度阈值，从频繁项集中生成强关联规则。<br><strong>Apriori性质</strong>：<br>如果一个项集A是频繁项集，那么它的非空子集B也是频繁项集。<br>或者：如果一个项集不是频繁项集，那它的超集也不是频繁项集。</p><p>FP-Growth算法</p><h1 id="集成"><a href="#集成" class="headerlink" title="集成"></a>集成</h1><p>降低误差<br>- 假设单个分类器误差 𝑝，分类器之间独立，𝑇个分类器采用投票进行预测，得到集成模型 𝐻<br>- 集成分类器误差为：<br>𝑇&#x3D;5, 𝑝&#x3D;0.1 时， Error𝐻&lt;0.01</p><ul><li>多数投票方法 (majority vote)</li><li>平均 (averaging)</li><li>加权平均 (weighted averaging)：如AdaBoost</li></ul><h2 id="Bagging算法"><a href="#Bagging算法" class="headerlink" title="Bagging算法"></a>Bagging算法</h2><p>优势：<br>- 特别适合用来提高那些方差大但偏差小的基模型(决策树，神经网络等)的预测性能<br>- 单个模型不稳定：对训练数据轻微的改变就能够造成分类器性能很明显的变化<br>- 使用Bagging可以综合投票结果，从而提升稳定性以及准确率<br>- 便于并行化。多个抽样数据的获取及基模型的训练互相没有关联，可以方便地进行并行计算</p><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><h4 id="决策树的局限性"><a href="#决策树的局限性" class="headerlink" title="决策树的局限性"></a>决策树的局限性</h4><h4 id="随机森林算法原理"><a href="#随机森林算法原理" class="headerlink" title="随机森林算法原理"></a>随机森林算法原理</h4><h4 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h4><h4 id="随机森林与特征选择"><a href="#随机森林与特征选择" class="headerlink" title="随机森林与特征选择"></a>随机森林与特征选择</h4><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>优点：<br>- 能够处理很高维度的数据，并且不用做特征选择<br>- 对特征之间存在的多重共线性不敏感，并且能够在一定程度上处理缺失数据和不均衡数据<br>- 在训练完后能够给出哪些特征比较重要<br>- 容易做成并行化方法<br>缺点：<br>- 处理噪音较大的小样本和低维数据集的问题上会过度拟合<br>- 相对于决策树，预测速度较慢<br>- 相对于决策树，模型可解释性较差</p><h4 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h4><h2 id="Boosting算法"><a href="#Boosting算法" class="headerlink" title="Boosting算法"></a>Boosting算法</h2><p>串行方式训练获得强分类器</p><h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>AdaBoost (Adaptive Boosting)是最有代表性的Boosting算法；<br>AdaBoost的核心思想是利用同一训练样本的不同加权版本，训练一组弱分类器，然后把这些弱分类器以加权的形式集成起来，形成一个最终的强分类器：</p><h4 id="分类器权重更新"><a href="#分类器权重更新" class="headerlink" title="分类器权重更新"></a>分类器权重更新</h4><h4 id="样本权重更新"><a href="#样本权重更新" class="headerlink" title="样本权重更新"></a>样本权重更新</h4><h4 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h4></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA/" class="category-chain-item">数据科学导论</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA/">#数据科学导论</a></div></div><div class="license-box my-3"><div class="license-title"><div>分类与回归</div><div>https://furthur509.github.io/2023/06/19/分类与回归/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Yang Mingxin</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年6月19日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2023/08/16/Leetcode-2682%E6%89%BE%E5%87%BA%E8%BD%AC%E5%9C%88%E6%B8%B8%E6%88%8F%E8%BE%93%E5%AE%B6/" title="Leetcode 2682找出转圈游戏输家"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Leetcode 2682找出转圈游戏输家</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/06/19/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/" title="聚类分析"><span class="hidden-mobile">聚类分析</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>