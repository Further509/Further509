<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Yang Mingxin"><meta name="keywords" content="blog"><meta name="description" content="Spell Correction拼写检查任务，实现语言模型和通道模型，并利用tkinter实现GUI I．EnvironmentPython 3.10.9 Package: nltk 3.7 and numpy 1.26.4 II．TheorySpell-checking involves distinguishing between non-word errors and real-word e"><meta property="og:type" content="article"><meta property="og:title" content="NLP-Spell Correction"><meta property="og:url" content="https://furthur509.github.io/2024/10/25/NLP-Spell%20Correction/index.html"><meta property="og:site_name" content="Yang Mingxin&#39;s Blog"><meta property="og:description" content="Spell Correction拼写检查任务，实现语言模型和通道模型，并利用tkinter实现GUI I．EnvironmentPython 3.10.9 Package: nltk 3.7 and numpy 1.26.4 II．TheorySpell-checking involves distinguishing between non-word errors and real-word e"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps1.png"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps2.png"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps3.png"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps4.png"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps5.png"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/image-20241025224526553.png"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps7.png"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps8.jpg"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps9.jpg"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps10.jpg"><meta property="og:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps11.jpg"><meta property="article:published_time" content="2024-10-25T14:49:07.000Z"><meta property="article:modified_time" content="2024-10-26T01:22:40.824Z"><meta property="article:author" content="Yang Mingxin"><meta property="article:tag" content="NLP"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://raw.githubusercontent.com/Further509/Picture/main/wps1.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>NLP-Spell Correction - Yang Mingxin&#39;s Blog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"furthur509.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:60,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Yang Mingxin&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/indexsecond.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="NLP-Spell Correction"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-10-25 22:49" pubdate>2024年10月25日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 23k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 195 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">NLP-Spell Correction</h1><p class="note note-info">本文最后更新于：2024年10月26日 上午</p><div class="markdown-body"><h1 id="Spell-Correction"><a href="#Spell-Correction" class="headerlink" title="Spell Correction"></a>Spell Correction</h1><p>拼写检查任务，实现语言模型和通道模型，并利用tkinter实现GUI</p><h2 id="I．Environment"><a href="#I．Environment" class="headerlink" title="I．Environment"></a>I．Environment</h2><p>Python 3.10.9</p><p>Package: nltk 3.7 and numpy 1.26.4</p><h2 id="II．Theory"><a href="#II．Theory" class="headerlink" title="II．Theory"></a>II．Theory</h2><p>Spell-checking involves distinguishing between non-word errors and real-word errors. Non-word errors occur when a word is spelled incorrectly to the extent that it does not exist, such as spelling “giraffe” as “graffe.” Real-word errors, on the other hand, involve correctly spelled words that are used incorrectly within a given context.</p><p>Detection of non-word spelling errors primarily relies on dictionary lookup to determine whether a word exists. Correcting non-word errors typically involves two main steps: first, generating candidate words that are similar to the misspelled word and correct; second, selecting the best correction from these candidates. The selection of the best correction can be achieved through methods such as calculating the weighted edit distance between the misspelled word and each candidate word, choosing the candidate with the shortest distance as the correction, or calculating noisy channel probabilities and selecting the highest probability candidate.</p><p>Handling real-word spelling errors involves generating a set of candidate corrections for each word w. Candidates can be generated based on similar pronunciation or spelling to w, ensuring that w itself is included in the candidate set. The best correction is then chosen from these candidates, often using methods like edit distance to select the candidate with the smallest distance from w, or applying a noisy channel model to choose the candidate with the highest posterior probability. These approaches are combined to select the candidate with the highest probability among candidates with equal edit distances.</p><p>This framework ensures effective handling of spelling errors in natural language processing applications.</p><h2 id="III．Data"><a href="#III．Data" class="headerlink" title="III．Data"></a>III．Data</h2><p><strong>Training corpus</strong></p><p>Reuters Corpus</p><p><strong>Test dataset</strong></p><p>testdata.txt</p><h2 id="IV．Model-Development"><a href="#IV．Model-Development" class="headerlink" title="IV．Model Development"></a>IV．Model Development</h2><h3 id="Language-model"><a href="#Language-model" class="headerlink" title="Language model"></a>Language model</h3><p>Language models evaluate the naturalness and grammatical correctness of sentences by assessing the probability of word occurrences in text. The sentence probability calculation formula is derived from the chain rule.</p><p>​	<img src="https://raw.githubusercontent.com/Further509/Picture/main/wps1.png" srcset="/img/loading.gif" lazyload alt="img"></p><p>Introducing the Markov assumption, given the previous k words, each word’s generation depends solely on these k preceding words. The formula then transforms into</p><p>​	<img src="https://raw.githubusercontent.com/Further509/Picture/main/wps2.png" srcset="/img/loading.gif" lazyload alt="img"></p><p>In natural language processing, the method where each word’s generation depends on the preceding N words is called N-gram. The 0th order is Unigram, 1st order is Bigram, and 2nd order is Trigram.</p><p>In language modeling, the issue of encountering probabilities of zero often arises, necessitating the use of smoothing methods. Here, I combine Add-k smoothing and interpolation smoothing for handling this issue.</p><p>interpolation smoothing：</p><p>​	<img src="https://raw.githubusercontent.com/Further509/Picture/main/wps3.png" srcset="/img/loading.gif" lazyload alt="img"></p><p>Among them : <img src="https://raw.githubusercontent.com/Further509/Picture/main/wps4.png" srcset="/img/loading.gif" lazyload alt="img">.</p><p>For calculating unigram, bigram, and trigram probabilities, we use Add-k smoothing.	<img src="https://raw.githubusercontent.com/Further509/Picture/main/wps5.png" srcset="/img/loading.gif" lazyload alt="img"></p><h3 id="Edit-Distance"><a href="#Edit-Distance" class="headerlink" title="Edit Distance"></a>Edit Distance</h3><p>Based on edit distance, the system can generate a list of candidate words similar to the original word. By constraining the edit distance within a reasonable range, we ensure that the generated candidate words include possible correct spelling forms. We filter out candidate words where the edit distance is less than or equal to 2 to obtain the list of candidates.</p><h3 id="Noisy-channel-model"><a href="#Noisy-channel-model" class="headerlink" title="Noisy channel model"></a>Noisy channel model</h3><p><img src="https://raw.githubusercontent.com/Further509/Picture/main/image-20241025224526553.png" srcset="/img/loading.gif" lazyload alt="Noisy channel model"></p><p>The system combines the candidate word list generated using edit distance with a noisy channel model to weight and evaluate the probability of each candidate word. This approach helps to exclude spelling suggestions that are unreasonable in context and improves the accuracy of selecting the correct correction by the system.</p><p>Assume word x has a spelling error. Now, to find the best candidate from the set V, the following calculation method can be used.</p><p>​	<img src="https://raw.githubusercontent.com/Further509/Picture/main/wps7.png" srcset="/img/loading.gif" lazyload></p><p>Where P(x|w) is derived from the noisy channel model, and P(w) is derived from the language model.</p><p>The channel model also employs Add-k smoothing to smooth the probabilities.</p><h2 id="V．Code-Implementation"><a href="#V．Code-Implementation" class="headerlink" title="V．Code Implementation"></a>V．Code Implementation</h2><p><strong>Data preprocessing</strong></p><p>preprocessing(ngram, cate)</p><p>Read the vocabulary from vocab.txt, read and preprocess the test data from testdata.txt, and process the corpus to form n-gram information.</p><p><strong>Load confusion matrix</strong></p><p>Here, we use the data from the paper ‘A Spelling Correction Program Based on a Noisy Channel Model’</p><p>loadConfusionMatrix():</p><p>Obtain addmatrix, submatrix, revmatrix, and delmatrix respectively.</p><p><strong>Language model</strong></p><p>interpolated_language_model(gram_count, V, data, lambdas, K&#x3D;0.0001)</p><p>Language model combining Add-k smoothing and interpolated smoothing</p><p><strong>Edit distance</strong></p><p>editType(candidate, word)</p><p>Identify the type of edit relative to the original word for candidate words.</p><p><img src="https://raw.githubusercontent.com/Further509/Picture/main/wps8.jpg" srcset="/img/loading.gif" lazyload alt="img"></p><p><strong>Retrieve candidate words</strong></p><p>get_candidate(trie, word, edit_distance&#x3D;2)</p><p>Retrieve words from the dictionary with an edit distance of less than or equal to 2 as candidate words.</p><p><img src="https://raw.githubusercontent.com/Further509/Picture/main/wps9.jpg" srcset="/img/loading.gif" lazyload alt="img"></p><p><strong>Noisy channel model</strong></p><p>channelModel(x, y, edit, corpus, k&#x3D;0.1)</p><p>Calculate channel model error probability</p><p><img src="https://raw.githubusercontent.com/Further509/Picture/main/wps10.jpg" srcset="/img/loading.gif" lazyload alt="img"></p><p><strong>Perform spell correction</strong></p><p>spell_correct(vocab, testdata, gram_count, corpus, V, trie, lambdas)</p><p>Perform spell correction on the test data, first addressing non-word errors, then handling real-word errors.</p><h2 id="VI．Result"><a href="#VI．Result" class="headerlink" title="VI．Result"></a>VI．Result</h2><p>Obtained by multiple adjustments of various parameter values:</p><table><thead><tr><th>Interpolated combination weights</th><th>Add-1</th><th>Add-k</th></tr></thead><tbody><tr><td>0.90 0.05 0.05</td><td>82.9%</td><td>88.8%</td></tr><tr><td>0.05 0.90 0.05</td><td>85.5%</td><td>89.2%</td></tr><tr><td>0.05 0.05 0.90</td><td>85.4%</td><td>89.2%</td></tr><tr><td>0.01 0.80 0.19</td><td>85.6%</td><td>89.7%</td></tr><tr><td>0.20 0.30 0.50</td><td>84.8%</td><td>89.3%</td></tr><tr><td>0.10 0.30 0.60</td><td>85.3%</td><td>89.5%</td></tr><tr><td>0.10 0.60 0.30</td><td>85.2%</td><td>89.4%</td></tr><tr><td>0.40 0.40 0.20</td><td>84.3%</td><td>89.2%</td></tr></tbody></table><p>The highest accuracy is <strong>89.7%</strong>, with interpolated combination weights of <strong>0.01, 0.80, and 0.19</strong>, using <strong>Add-k</strong> smoothing.</p><h2 id="VII．GUI"><a href="#VII．GUI" class="headerlink" title="VII．GUI"></a>VII．GUI</h2><p>The packaged executable file “main_script.exe” is located in “&#x2F;GUI&#x2F;dist&#x2F;main_script”. Double-click to run it.</p><p><img src="https://raw.githubusercontent.com/Further509/Picture/main/wps11.jpg" srcset="/img/loading.gif" lazyload alt="img"></p><h2 id="VIII．Reference"><a href="#VIII．Reference" class="headerlink" title="VIII．Reference"></a>VIII．Reference</h2><p>[1] Kernighan, M. D., Church, K., &amp; Gale, W. A. (1990). A spelling correction program based on a noisy channel model. In COLING 1990 Volume 2: Papers presented to the 13th International Conference on Computational Linguistics.</p><p>[2] Jayanthi, S. M., Pruthi, D., &amp; Neubig, G. (2020). Neuspell: A neural spelling correction toolkit. arXiv preprint arXiv:2010.11085.</p><p>[3] <a target="_blank" rel="noopener" href="https://blog.csdn.net/BeforeEasy/article/details/104104731">如何写一个拼写纠错器 – how to write a spelling corrector-CSDN博客</a></p><p>[4] <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36134437/article/details/103146390">https://blog.csdn.net/qq_36134437/article/details/103146390</a></p><p>[5] <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41230076/article/details/105474437">NLP-拼写纠错（spell correction）实战_nlp correction插件-CSDN博客</a></p><h2 id="IX-Code"><a href="#IX-Code" class="headerlink" title="IX. Code"></a>IX. Code</h2><p>main.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br><span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> word_tokenize<br><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> reuters<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict, deque<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> ast<br><br><br><span class="hljs-comment">#预处理函数，测试数据，语料库和词典</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocessing</span>(<span class="hljs-params">ngram, cate</span>):<br>    <span class="hljs-comment"># 读取词汇表</span><br>    vocabpath = <span class="hljs-string">&#x27;./vocab.txt&#x27;</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(vocabpath, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> vocabfile:<br>        <span class="hljs-comment"># 从词汇表文件中读取每一行，去掉首尾空格后存储到 vocab_list 列表中</span><br>        vocab_list = [line.strip() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> vocabfile]<br>    <br>    <span class="hljs-comment"># 读取测试数据</span><br>    testpath = <span class="hljs-string">&#x27;./testdata.txt&#x27;</span><br>    testdata = []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(testpath, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> testfile:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> testfile:<br>            <span class="hljs-comment"># 将每行数据用制表符拆分成三个部分：句子标识符、错误计数和实际句子</span><br>            item = line.split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>            <span class="hljs-comment"># 对句子进行分词</span><br>            item[<span class="hljs-number">2</span>] = word_tokenize(item[<span class="hljs-number">2</span>])<br>            <span class="hljs-comment"># 在句子的开头和结尾添加特殊标记 &lt;s&gt; 和 &lt;/s&gt;</span><br>            item[<span class="hljs-number">2</span>] = [<span class="hljs-string">&#x27;&lt;s&gt;&#x27;</span>] + item[<span class="hljs-number">2</span>] + [<span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]<br>            <span class="hljs-comment"># 将处理后的句子添加到 testdata 列表中</span><br>            testdata.append(item)<br>    <br>    <span class="hljs-comment"># 预处理语料库</span><br>    corpus_raw_text = reuters.sents(categories=cate)<br>    corpus_text = []<br>    gram_count = defaultdict(<span class="hljs-built_in">int</span>)<br>    vocab_corpus = <span class="hljs-built_in">set</span>()<br><br>    <span class="hljs-keyword">for</span> sents <span class="hljs-keyword">in</span> corpus_raw_text:<br>        <span class="hljs-comment"># 在每个句子的开头和结尾添加特殊标记 &lt;s&gt; 和 &lt;/s&gt;</span><br>        sents = [<span class="hljs-string">&#x27;&lt;s&gt;&#x27;</span>] + sents + [<span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]<br>        <span class="hljs-comment"># 将处理后的句子添加到 corpus_text 中</span><br>        corpus_text.extend(sents)<br>        <span class="hljs-comment"># 更新词汇集合 vocab_corpus</span><br>        vocab_corpus.update(sents)<br>        <br>        <span class="hljs-comment"># 统计不同长度的 n-grams</span><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, ngram + <span class="hljs-number">2</span>):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n, <span class="hljs-built_in">len</span>(sents) + <span class="hljs-number">1</span>):<br>                <span class="hljs-comment"># 提取 n-gram</span><br>                gram = <span class="hljs-string">&#x27; &#x27;</span>.join(sents[i - n: i])<br>                <span class="hljs-comment"># 统计 n-gram 的频率</span><br>                gram_count[gram] += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 计算语料库中的独特词汇数量</span><br>    V = <span class="hljs-built_in">len</span>(vocab_corpus)<br>    <span class="hljs-comment"># 返回词汇表、测试数据、n-gram 统计信息、词汇集合、处理后的语料库和词汇数量</span><br>    <span class="hljs-keyword">return</span> vocab_list, testdata, gram_count, <span class="hljs-built_in">list</span>(vocab_corpus), corpus_text, V<br><br><br><br><span class="hljs-comment">#路透社语料库</span><br>cate = reuters.categories()<br><br><br><span class="hljs-comment">#结合语料库进行预处理</span><br>vocab, testdata, gram_count, vocab_corpus, corpus_text, V = preprocessing(<span class="hljs-number">2</span>, cate)  <span class="hljs-comment"># 使用trigram</span><br><br><br><span class="hljs-comment"># 从外部数据文件加载混淆矩阵</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loadConfusionMatrix</span>():<br>    <span class="hljs-comment"># 加载添加操作的混淆矩阵</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;addconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        addmatrix = ast.literal_eval(f.read())<br>    <br>    <span class="hljs-comment"># 加载替换操作的混淆矩阵</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;subconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        submatrix = ast.literal_eval(f.read())<br>    <br>    <span class="hljs-comment"># 加载颠倒操作的混淆矩阵</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;revconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        revmatrix = ast.literal_eval(f.read())<br>    <br>    <span class="hljs-comment"># 加载删除操作的混淆矩阵</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;delconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        delmatrix = ast.literal_eval(f.read())<br>    <br>    <span class="hljs-comment"># 返回所有混淆矩阵</span><br>    <span class="hljs-keyword">return</span> addmatrix, submatrix, revmatrix, delmatrix<br><br><br><br><span class="hljs-comment">#获取混淆矩阵</span><br>addmatrix, submatrix, revmatrix, delmatrix = loadConfusionMatrix()<br><br><span class="hljs-comment"># %%</span><br>END = <span class="hljs-string">&#x27;$&#x27;</span>  <span class="hljs-comment"># 用于表示单词结束的特殊标记</span><br><br><span class="hljs-comment"># 创建字典树（trie）</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_trie</span>(<span class="hljs-params">vocab</span>):<br>    trie = &#123;&#125;  <span class="hljs-comment"># 初始化空字典树</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> vocab:<br>        t = trie  <span class="hljs-comment"># 从根节点开始插入单词</span><br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> word:<br>            <span class="hljs-keyword">if</span> c <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> t:<br>                t[c] = &#123;&#125;  <span class="hljs-comment"># 如果当前字符不在当前节点中，创建一个新的子节点</span><br>            t = t[c]  <span class="hljs-comment"># 移动到当前字符的子节点</span><br>        t[END] = &#123;&#125;  <span class="hljs-comment"># 在单词的末尾添加结束标记</span><br>    <span class="hljs-keyword">return</span> trie  <span class="hljs-comment"># 返回构建好的字典树</span><br><br><br><br><span class="hljs-comment">#将词典创建字典树，加快查找效率</span><br>trie = make_trie(vocab)<br><br><br><span class="hljs-comment">#候选词和原词的编辑类型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">editType</span>(<span class="hljs-params">candidate, word</span>):<br>    <span class="hljs-comment"># 如果候选词和原词长度相等</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(candidate) == <span class="hljs-built_in">len</span>(word):<br>        <span class="hljs-comment"># 检查字符替换错误</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(candidate)):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;sub&#x27;</span>, candidate[i], word[i], (candidate[i], word[i])<br>    <span class="hljs-comment"># 如果候选词长度比原词短1</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(candidate) + <span class="hljs-number">1</span> == <span class="hljs-built_in">len</span>(word):<br>        <span class="hljs-comment"># 检查字符删除错误</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(candidate)):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;del&#x27;</span>, candidate[i], word[i], (candidate[i], word[i + <span class="hljs-number">1</span>])<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;del&#x27;</span>, candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>, (candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-comment"># 如果候选词长度比原词长1</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(candidate) == <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>:<br>        <span class="hljs-comment"># 检查字符添加错误</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word)):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;add&#x27;</span>, candidate[i], word[i], (candidate[i], word[i])<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;add&#x27;</span>, candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>, (candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-comment"># 如果候选词和原词长度相等（再次检查字符调换错误）</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(candidate) == <span class="hljs-built_in">len</span>(word):<br>        <span class="hljs-comment"># 检查字符调换错误</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(candidate) - <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i] <span class="hljs-keyword">and</span> candidate[i + <span class="hljs-number">1</span>] != word[i + <span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">if</span> candidate[i] == word[i + <span class="hljs-number">1</span>] <span class="hljs-keyword">and</span> candidate[i + <span class="hljs-number">1</span>] == word[i]:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;rev&#x27;</span>, candidate[i], word[i], (candidate[i], candidate[i + <span class="hljs-number">1</span>])<br>    <span class="hljs-comment"># 如果没有匹配的编辑类型，返回 None</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br><br><span class="hljs-comment"># 结合加K和插值平滑的语言模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">interpolated_language_model</span>(<span class="hljs-params">gram_count, V, data, lambdas, K=<span class="hljs-number">0.0001</span></span>):<br>    <span class="hljs-comment"># 提取插值平滑系数</span><br>    unigram_lambda, bigram_lambda, trigram_lambda = lambdas<br>    total_log_prob = <span class="hljs-number">0</span>  <span class="hljs-comment"># 初始化总对数概率</span><br>    total_count = <span class="hljs-built_in">sum</span>(gram_count.values())  <span class="hljs-comment"># 总的 n-gram 计数</span><br>    <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)):<br>        unigram = data[i]  <span class="hljs-comment"># 当前词（Unigram）</span><br>        bigram = <span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">1</span>:i+<span class="hljs-number">1</span>]) <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>  <span class="hljs-comment"># 当前词和前一个词（Bigram）</span><br>        trigram = <span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">2</span>:i+<span class="hljs-number">1</span>]) <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>  <span class="hljs-comment"># 当前词和前两个词（Trigram）</span><br>        <br>        <span class="hljs-comment"># Unigram 概率计算，使用 K-平滑</span><br>        unigram_prob = (gram_count[unigram] + K) / (total_count + K * V)<br>        <br>        <span class="hljs-keyword">if</span> bigram:<br>            <span class="hljs-comment"># Bigram 概率计算，使用 K-平滑</span><br>            bigram_prob = (gram_count[bigram] + K) / (gram_count[data[i-<span class="hljs-number">1</span>]] + K * V) <span class="hljs-keyword">if</span> data[i-<span class="hljs-number">1</span>] <span class="hljs-keyword">in</span> gram_count <span class="hljs-keyword">else</span> K / V<br>        <span class="hljs-keyword">else</span>:<br>            bigram_prob = <span class="hljs-number">0</span>  <span class="hljs-comment"># 如果没有 Bigram，则概率为 0</span><br>        <br>        <span class="hljs-keyword">if</span> trigram:<br>            <span class="hljs-comment"># Trigram 概率计算，使用 K-平滑</span><br>            trigram_prob = (gram_count[trigram] + K) / (gram_count[<span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">2</span>:i])] + K * V) <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">2</span>:i]) <span class="hljs-keyword">in</span> gram_count <span class="hljs-keyword">else</span> K / V<br>        <span class="hljs-keyword">else</span>:<br>            trigram_prob = <span class="hljs-number">0</span>  <span class="hljs-comment"># 如果没有 Trigram，则概率为 0</span><br>        <br>        <span class="hljs-comment"># 计算插值平滑后的概率</span><br>        interpolated_prob = (unigram_lambda * unigram_prob +<br>                             bigram_lambda * bigram_prob +<br>                             trigram_lambda * trigram_prob)<br>                             <br>        <span class="hljs-comment"># 将插值平滑后的概率取对数并加到总对数概率中</span><br>        total_log_prob += np.log(interpolated_prob)<br>        <br>    <span class="hljs-keyword">return</span> total_log_prob  <span class="hljs-comment"># 返回总对数概率</span><br><br><br><span class="hljs-comment"># 获取候选词</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_candidate</span>(<span class="hljs-params">trie, word, edit_distance=<span class="hljs-number">2</span></span>):<br>    <span class="hljs-comment"># 初始化队列，包含（字典树，词，路径，编辑距离）的元组</span><br>    que = deque([(trie, word, <span class="hljs-string">&#x27;&#x27;</span>, edit_distance)])<br>    <br>    <span class="hljs-comment"># 使用广度优先搜索算法遍历队列</span><br>    <span class="hljs-keyword">while</span> que:<br>        <span class="hljs-comment"># 从队列中取出一个元素</span><br>        trie, word, path, edit_distance = que.popleft()<br>        <br>        <span class="hljs-comment"># 如果词已经处理完</span><br>        <span class="hljs-keyword">if</span> word == <span class="hljs-string">&#x27;&#x27;</span>:<br>            <span class="hljs-comment"># 如果路径在字典树中标记为结束（即一个完整单词）</span><br>            <span class="hljs-keyword">if</span> END <span class="hljs-keyword">in</span> trie:<br>                <span class="hljs-keyword">yield</span> path  <span class="hljs-comment"># 生成候选词</span><br>            <br>            <span class="hljs-comment"># 如果编辑距离还未耗尽，继续生成候选词</span><br>            <span class="hljs-keyword">if</span> edit_distance &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> trie:<br>                    <span class="hljs-keyword">if</span> k != END:  <span class="hljs-comment"># 不处理结束标记</span><br>                        <span class="hljs-comment"># 将新生成的路径和剩余编辑距离放入队列</span><br>                        que.appendleft((trie[k], <span class="hljs-string">&#x27;&#x27;</span>, path + k, edit_distance - <span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 如果当前字符在字典树中</span><br>            <span class="hljs-keyword">if</span> word[<span class="hljs-number">0</span>] <span class="hljs-keyword">in</span> trie:<br>                <span class="hljs-comment"># 将当前字符匹配的路径放入队列，继续处理剩余词</span><br>                que.appendleft((trie[word[<span class="hljs-number">0</span>]], word[<span class="hljs-number">1</span>:], path + word[<span class="hljs-number">0</span>], edit_distance))<br>            <br>            <span class="hljs-comment"># 如果编辑距离还未耗尽，尝试其他编辑操作生成候选词</span><br>            <span class="hljs-keyword">if</span> edit_distance &gt; <span class="hljs-number">0</span>:<br>                edit_distance -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> trie.keys() - &#123;word[<span class="hljs-number">0</span>], END&#125;:<br>                    <span class="hljs-comment"># 替换字符操作</span><br>                    que.append((trie[k], word[<span class="hljs-number">1</span>:], path + k, edit_distance))<br>                    <span class="hljs-comment"># 添加字符操作</span><br>                    que.append((trie[k], word, path + k, edit_distance))<br>                <br>                <span class="hljs-comment"># 删除字符操作</span><br>                que.append((trie, word[<span class="hljs-number">1</span>:], path, edit_distance))<br>                <br>                <span class="hljs-comment"># 调换字符操作</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(word) &gt; <span class="hljs-number">1</span>:<br>                    que.append((trie, word[<span class="hljs-number">1</span>] + word[<span class="hljs-number">0</span>] + word[<span class="hljs-number">2</span>:], path, edit_distance))<br><br><br><span class="hljs-comment"># 计算信道模型错误概率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">channelModel</span>(<span class="hljs-params">x, y, edit, corpus, k=<span class="hljs-number">0.01</span></span>):<br>    <span class="hljs-comment"># 将语料库转换为一个字符串，以便进行计数</span><br>    corpus_str = <span class="hljs-string">&#x27; &#x27;</span>.join(corpus)<br>    <span class="hljs-comment"># 语料库的长度</span><br>    corpus_len = <span class="hljs-built_in">len</span>(corpus)<br><br>    <span class="hljs-comment"># 处理添加字符的情况</span><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;add&#x27;</span>:<br>        <span class="hljs-comment"># 获取在添加混淆矩阵中的频次</span><br>        count_xy = addmatrix.get(x + y, <span class="hljs-number">0</span>)<br>        <span class="hljs-comment"># 计算x或y的频次，根据x是否为起始标记来决定</span><br>        count_y = corpus_str.count(<span class="hljs-string">&#x27; &#x27;</span> + y) <span class="hljs-keyword">if</span> x == <span class="hljs-string">&#x27;#&#x27;</span> <span class="hljs-keyword">else</span> corpus_str.count(x)<br>        <span class="hljs-comment"># 使用加K平滑计算添加错误的概率</span><br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_y + k * corpus_len) <span class="hljs-keyword">if</span> count_y <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-comment"># 处理替换字符的情况</span><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;sub&#x27;</span>:<br>        <span class="hljs-comment"># 获取在替换混淆矩阵中的频次</span><br>        count_xy = submatrix.get((x + y)[:<span class="hljs-number">2</span>], <span class="hljs-number">0</span>)<br>        <span class="hljs-comment"># 计算y的频次</span><br>        count_y = corpus_str.count(y)<br>        <span class="hljs-comment"># 使用加K平滑计算替换错误的概率</span><br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_y + k * corpus_len) <span class="hljs-keyword">if</span> count_y <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-comment"># 处理调换字符的情况</span><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;rev&#x27;</span>:<br>        <span class="hljs-comment"># 获取在调换混淆矩阵中的频次</span><br>        count_xy = revmatrix.get(x + y, <span class="hljs-number">0</span>)<br>        <span class="hljs-comment"># 计算x和y调换后在语料库中的频次</span><br>        count_xy_in_corpus = corpus_str.count(x + y)<br>        <span class="hljs-comment"># 使用加K平滑计算调换错误的概率</span><br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_xy_in_corpus + k * corpus_len) <span class="hljs-keyword">if</span> count_xy_in_corpus <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-comment"># 处理删除字符的情况</span><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;del&#x27;</span>:<br>        <span class="hljs-comment"># 获取在删除混淆矩阵中的频次</span><br>        count_xy = delmatrix.get(x + y, <span class="hljs-number">0</span>)<br>        <span class="hljs-comment"># 计算x和y在语料库中的频次</span><br>        count_xy_in_corpus = corpus_str.count(x + y)<br>        <span class="hljs-comment"># 使用加K平滑计算删除错误的概率</span><br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_xy_in_corpus + k * corpus_len) <span class="hljs-keyword">if</span> count_xy_in_corpus <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-comment"># 如果没有匹配的编辑操作，返回一个默认的概率</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / corpus_len<br><br><br><span class="hljs-comment"># 拼写纠正函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">spell_correct</span>(<span class="hljs-params">vocab, testdata, gram_count, corpus, V, trie, lambdas</span>):<br>    resultpath = <span class="hljs-string">&#x27;./result.txt&#x27;</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(resultpath, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> resultfile:<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> testdata:<br>            corrected_sentence = item[<span class="hljs-number">2</span>][<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>]  <span class="hljs-comment"># 去掉&lt;s&gt; 和 &lt;/s&gt;，只保留句子部分</span><br>            error_count = <span class="hljs-built_in">int</span>(item[<span class="hljs-number">1</span>])  <span class="hljs-comment"># 错误数量</span><br>            corrected_words = <span class="hljs-number">0</span>  <span class="hljs-comment"># 纠正的单词数量</span><br>            non_word_errors = <span class="hljs-number">0</span>  <span class="hljs-comment"># 处理的非词错误数量</span><br>            modified_indices = <span class="hljs-built_in">set</span>()  <span class="hljs-comment"># 记录已经修改的索引</span><br><br>            <span class="hljs-comment"># 处理非词错误</span><br>            <span class="hljs-keyword">for</span> i, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(corrected_sentence):<br>                <span class="hljs-keyword">if</span> non_word_errors &gt;= error_count:<br>                    <span class="hljs-keyword">break</span><br><br>                <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> vocab:  <span class="hljs-comment"># 如果词不在词汇表中，可能是非词错误</span><br>                    <span class="hljs-comment"># 获取编辑距离为1或2的候选词</span><br>                    candidates = <span class="hljs-built_in">list</span>(get_candidate(trie, word, edit_distance=<span class="hljs-number">1</span>)) <span class="hljs-keyword">or</span> <span class="hljs-built_in">list</span>(get_candidate(trie, word, edit_distance=<span class="hljs-number">2</span>))<br>                    candi_proba = []<br><br>                    <span class="hljs-comment"># 对每个候选词计算其概率</span><br>                    <span class="hljs-keyword">for</span> candidate <span class="hljs-keyword">in</span> candidates:<br>                        edit = editType(candidate, word)  <span class="hljs-comment"># 获取编辑类型</span><br>                        <span class="hljs-keyword">if</span> edit <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                            candi_proba.append(interpolated_language_model(gram_count, V, [candidate], lambdas))<br>                            <span class="hljs-keyword">continue</span><br><br>                        x, y = <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span><br>                        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(edit) == <span class="hljs-number">4</span>:<br>                            x, y = edit[<span class="hljs-number">3</span>][<span class="hljs-number">0</span>], edit[<span class="hljs-number">3</span>][<span class="hljs-number">1</span>]<br>                        channel_p = np.log(channelModel(x, y, edit[<span class="hljs-number">0</span>].lower(), corpus)) <span class="hljs-keyword">if</span> edit <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br><br>                        <span class="hljs-comment"># 构建前后文环境</span><br>                        word_index = i + <span class="hljs-number">1</span><br>                        pre_phase = item[<span class="hljs-number">2</span>][word_index - <span class="hljs-number">2</span>: word_index] + [candidate]<br>                        post_phase = [candidate] + item[<span class="hljs-number">2</span>][word_index + <span class="hljs-number">1</span>: word_index + <span class="hljs-number">3</span>]<br><br>                        <span class="hljs-comment"># 使用插值平滑计算概率</span><br>                        p = (<span class="hljs-number">0.4</span> * interpolated_language_model(gram_count, V, pre_phase, lambdas) +<br>                             <span class="hljs-number">0.4</span> * interpolated_language_model(gram_count, V, post_phase, lambdas) +<br>                             <span class="hljs-number">0.2</span> * channel_p)<br>                        candi_proba.append(p)<br><br>                    <span class="hljs-comment"># 选择概率最高的候选词进行纠正</span><br>                    <span class="hljs-keyword">if</span> candi_proba:<br>                        index = candi_proba.index(<span class="hljs-built_in">max</span>(candi_proba))<br>                        corrected_sentence[i] = candidates[index]<br>                        corrected_words += <span class="hljs-number">1</span><br>                        modified_indices.add(i)<br>                        non_word_errors += <span class="hljs-number">1</span><br><br>            <span class="hljs-comment"># 处理真词错误</span><br>            <span class="hljs-keyword">if</span> corrected_words &lt; error_count:<br>                <span class="hljs-keyword">for</span> i, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(corrected_sentence):<br>                    <span class="hljs-keyword">if</span> corrected_words &gt;= error_count:<br>                        <span class="hljs-keyword">break</span><br><br>                    <span class="hljs-keyword">if</span> i <span class="hljs-keyword">in</span> modified_indices <span class="hljs-keyword">or</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> vocab:  <span class="hljs-comment"># 已经处理过非词错误或者是真词错误</span><br>                        <span class="hljs-keyword">continue</span><br><br>                    <span class="hljs-comment"># 获取编辑距离为1或2的候选词</span><br>                    candidates = <span class="hljs-built_in">list</span>(get_candidate(trie, word, edit_distance=<span class="hljs-number">1</span>)) <span class="hljs-keyword">or</span> <span class="hljs-built_in">list</span>(get_candidate(trie, word, edit_distance=<span class="hljs-number">2</span>))<br>                    candi_proba = []<br><br>                    <span class="hljs-comment"># 对每个候选词计算其概率</span><br>                    <span class="hljs-keyword">for</span> candidate <span class="hljs-keyword">in</span> candidates:<br>                        <span class="hljs-keyword">if</span> candidate == word:<br>                            <span class="hljs-keyword">continue</span><br><br>                        edit = editType(candidate, word)<br>                        <span class="hljs-keyword">if</span> edit <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                            candi_proba.append(interpolated_language_model(gram_count, V, [candidate], lambdas))<br>                            <span class="hljs-keyword">continue</span><br><br>                        x, y = <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span><br>                        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(edit) == <span class="hljs-number">4</span>:<br>                            x, y = edit[<span class="hljs-number">3</span>][<span class="hljs-number">0</span>], edit[<span class="hljs-number">3</span>][<span class="hljs-number">1</span>]<br>                        channel_p = np.log(channelModel(x, y, edit[<span class="hljs-number">0</span>].lower(), corpus)) <span class="hljs-keyword">if</span> edit <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br><br>                        <span class="hljs-comment"># 构建前后文环境</span><br>                        word_index = i + <span class="hljs-number">1</span><br>                        pre_phase = item[<span class="hljs-number">2</span>][word_index - <span class="hljs-number">2</span>: word_index] + [candidate]<br>                        post_phase = [candidate] + item[<span class="hljs-number">2</span>][word_index + <span class="hljs-number">1</span>: word_index + <span class="hljs-number">3</span>]<br><br>                        <span class="hljs-comment"># 使用插值平滑计算概率</span><br>                        p = (<span class="hljs-number">0.4</span> * interpolated_language_model(gram_count, V, pre_phase, lambdas) +<br>                             <span class="hljs-number">0.4</span> * interpolated_language_model(gram_count, V, post_phase, lambdas) +<br>                             <span class="hljs-number">0.2</span> * channel_p)<br>                        candi_proba.append(p)<br><br>                    <span class="hljs-comment"># 选择概率最高的候选词进行纠正</span><br>                    <span class="hljs-keyword">if</span> candi_proba:<br>                        index = candi_proba.index(<span class="hljs-built_in">max</span>(candi_proba))<br>                        corrected_sentence[i] = candidates[index]<br>                        corrected_words += <span class="hljs-number">1</span><br><br>            <span class="hljs-comment"># 将纠正后的句子写入结果文件</span><br>            corrected_sentence_str = <span class="hljs-string">&#x27; &#x27;</span>.join(corrected_sentence)<br>            <span class="hljs-comment"># 修正常见的标点间距问题</span><br>            corrected_sentence_str = corrected_sentence_str.replace(<span class="hljs-string">&quot; &#x27;s&quot;</span>, <span class="hljs-string">&quot;&#x27;s&quot;</span>).replace(<span class="hljs-string">&quot; ,&quot;</span>, <span class="hljs-string">&quot;,&quot;</span>).replace(<span class="hljs-string">&quot; .&quot;</span>, <span class="hljs-string">&quot;.&quot;</span>).replace(<span class="hljs-string">&quot; ?&quot;</span>, <span class="hljs-string">&quot;?&quot;</span>).replace(<span class="hljs-string">&quot; !&quot;</span>, <span class="hljs-string">&quot;!&quot;</span>).replace(<span class="hljs-string">&quot; ;&quot;</span>, <span class="hljs-string">&quot;;&quot;</span>).replace(<span class="hljs-string">&quot; :&quot;</span>, <span class="hljs-string">&quot;:&quot;</span>).replace(<span class="hljs-string">&quot; (&quot;</span>, <span class="hljs-string">&quot;(&quot;</span>).replace(<span class="hljs-string">&quot; )&quot;</span>, <span class="hljs-string">&quot;)&quot;</span>)<br>            resultfile.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;item[<span class="hljs-number">0</span>]&#125;</span>\t<span class="hljs-subst">&#123;corrected_sentence_str&#125;</span>\n&quot;</span>)<br><br><br><span class="hljs-comment"># 运行拼写纠正</span><br>lambdas = (<span class="hljs-number">0.01</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.19</span>)  <span class="hljs-comment"># 设定插值平滑参数</span><br>spell_correct(vocab, testdata, gram_count, corpus_text, V, trie, lambdas)<br><br></code></pre></td></tr></table></figure><p>eval.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br>anspath=<span class="hljs-string">&#x27;./ans.txt&#x27;</span><br>resultpath=<span class="hljs-string">&#x27;./result.txt&#x27;</span><br>ansfile=<span class="hljs-built_in">open</span>(anspath,<span class="hljs-string">&#x27;r&#x27;</span>)<br>resultfile=<span class="hljs-built_in">open</span>(resultpath,<span class="hljs-string">&#x27;r&#x27;</span>)<br>count=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br>    ansline=ansfile.readline().split(<span class="hljs-string">&#x27;\t&#x27;</span>)[<span class="hljs-number">1</span>]<br>    ansset=<span class="hljs-built_in">set</span>(nltk.word_tokenize(ansline))<br>    resultline=resultfile.readline().split(<span class="hljs-string">&#x27;\t&#x27;</span>)[<span class="hljs-number">1</span>]<br>    resultset=<span class="hljs-built_in">set</span>(nltk.word_tokenize(resultline))<br>    <span class="hljs-keyword">if</span> ansset==resultset:<br>        count+=<span class="hljs-number">1</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy is : %.2f%%&quot;</span> % (count*<span class="hljs-number">1.00</span>/<span class="hljs-number">10</span>))<br><br></code></pre></td></tr></table></figure><p>GUI.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br><span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> word_tokenize<br><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> reuters<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter, defaultdict, deque<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> ast<br><span class="hljs-keyword">import</span> tkinter <span class="hljs-keyword">as</span> tk<br><span class="hljs-keyword">from</span> tkinter <span class="hljs-keyword">import</span> scrolledtext<br><br><span class="hljs-comment"># 预处理函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocessing</span>(<span class="hljs-params">ngram, cate</span>):<br>    <span class="hljs-comment"># 读取词汇表</span><br>    vocabpath = <span class="hljs-string">&#x27;./vocab.txt&#x27;</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(vocabpath, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> vocabfile:<br>        vocab_list = [line.strip() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> vocabfile]<br>    <br>    corpus_raw_text = reuters.sents(categories=cate)<br>    corpus_text = []<br>    gram_count = defaultdict(<span class="hljs-built_in">int</span>)<br>    vocab_corpus = <span class="hljs-built_in">set</span>()<br><br>    <span class="hljs-keyword">for</span> sents <span class="hljs-keyword">in</span> corpus_raw_text:<br>        sents = [<span class="hljs-string">&#x27;&lt;s&gt;&#x27;</span>] + sents + [<span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]<br>        corpus_text.extend(sents)<br>        vocab_corpus.update(sents)<br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, ngram + <span class="hljs-number">2</span>):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n, <span class="hljs-built_in">len</span>(sents) + <span class="hljs-number">1</span>):<br>                gram = <span class="hljs-string">&#x27; &#x27;</span>.join(sents[i - n: i])<br>                gram_count[gram] += <span class="hljs-number">1</span><br><br>    V = <span class="hljs-built_in">len</span>(vocab_corpus)<br>    <span class="hljs-keyword">return</span> vocab_list, gram_count, <span class="hljs-built_in">list</span>(vocab_corpus), corpus_text, V<br><br><span class="hljs-comment"># 路透社语料库</span><br>cate = reuters.categories()<br><br><span class="hljs-comment"># 结合语料库进行预处理</span><br>vocab, gram_count, vocab_corpus, corpus_text, V = preprocessing(<span class="hljs-number">2</span>, cate)<br><br><span class="hljs-comment"># 从外部数据文件加载混淆矩阵</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loadConfusionMatrix</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;addconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        addmatrix = ast.literal_eval(f.read())<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;subconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        submatrix = ast.literal_eval(f.read())<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;revconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        revmatrix = ast.literal_eval(f.read())<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;delconfusion.data&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        delmatrix = ast.literal_eval(f.read())<br>    <span class="hljs-keyword">return</span> addmatrix, submatrix, revmatrix, delmatrix<br><br>addmatrix, submatrix, revmatrix, delmatrix = loadConfusionMatrix()<br><br>END = <span class="hljs-string">&#x27;$&#x27;</span>  <span class="hljs-comment"># 用于表示单词结束的特殊标记</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_trie</span>(<span class="hljs-params">vocab</span>):<br>    trie = &#123;&#125;<br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> vocab:<br>        t = trie<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> word:<br>            <span class="hljs-keyword">if</span> c <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> t:<br>                t[c] = &#123;&#125;<br>            t = t[c]<br>        t[END] = &#123;&#125;<br>    <span class="hljs-keyword">return</span> trie<br><br>trie = make_trie(vocab)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">editType</span>(<span class="hljs-params">candidate, word</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(candidate) == <span class="hljs-built_in">len</span>(word):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(candidate)):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;sub&#x27;</span>, candidate[i], word[i], (candidate[i], word[i])<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(candidate) + <span class="hljs-number">1</span> == <span class="hljs-built_in">len</span>(word):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(candidate)):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;del&#x27;</span>, candidate[i], word[i], (candidate[i], word[i + <span class="hljs-number">1</span>])<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;del&#x27;</span>, candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>, (candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(candidate) == <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word)):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;add&#x27;</span>, candidate[i], word[i], (candidate[i], word[i])<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;add&#x27;</span>, candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>, (candidate[-<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(candidate) == <span class="hljs-built_in">len</span>(word):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(candidate) - <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> candidate[i] != word[i] <span class="hljs-keyword">and</span> candidate[i + <span class="hljs-number">1</span>] != word[i + <span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">if</span> candidate[i] == word[i + <span class="hljs-number">1</span>] <span class="hljs-keyword">and</span> candidate[i + <span class="hljs-number">1</span>] == word[i]:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;rev&#x27;</span>, candidate[i], word[i], (candidate[i], candidate[i + <span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">interpolated_language_model</span>(<span class="hljs-params">gram_count, V, data, lambdas, K=<span class="hljs-number">0.001</span></span>):<br>    unigram_lambda, bigram_lambda, trigram_lambda = lambdas<br>    total_log_prob = <span class="hljs-number">0</span><br>    total_count = <span class="hljs-built_in">sum</span>(gram_count.values())<br>    <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)):<br>        unigram = data[i]<br>        bigram = <span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">1</span>:i+<span class="hljs-number">1</span>]) <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>        trigram = <span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">2</span>:i+<span class="hljs-number">1</span>]) <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>        <br>        unigram_prob = (gram_count[unigram] + K) / (total_count + K * V)<br>        <br>        <span class="hljs-keyword">if</span> bigram:<br>            bigram_prob = (gram_count[bigram] + K) / (gram_count[data[i-<span class="hljs-number">1</span>]] + K * V) <span class="hljs-keyword">if</span> data[i-<span class="hljs-number">1</span>] <span class="hljs-keyword">in</span> gram_count <span class="hljs-keyword">else</span> K / V<br>        <span class="hljs-keyword">else</span>:<br>            bigram_prob = <span class="hljs-number">0</span><br>        <br>        <span class="hljs-keyword">if</span> trigram:<br>            trigram_prob = (gram_count[trigram] + K) / (gram_count[<span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">2</span>:i])] + K * V) <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27; &#x27;</span>.join(data[i-<span class="hljs-number">2</span>:i]) <span class="hljs-keyword">in</span> gram_count <span class="hljs-keyword">else</span> K / V<br>        <span class="hljs-keyword">else</span>:<br>            trigram_prob = <span class="hljs-number">0</span><br>        <br>        interpolated_prob = (unigram_lambda * unigram_prob +<br>                             bigram_lambda * bigram_prob +<br>                             trigram_lambda * trigram_prob)<br>                             <br>        total_log_prob += np.log(interpolated_prob)<br>        <br>    <span class="hljs-keyword">return</span> total_log_prob<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_candidate</span>(<span class="hljs-params">trie, word, edit_distance=<span class="hljs-number">1</span></span>):<br>    que = deque([(trie, word, <span class="hljs-string">&#x27;&#x27;</span>, edit_distance)])<br>    <br>    <span class="hljs-keyword">while</span> que:<br>        trie, word, path, edit_distance = que.popleft()<br>        <br>        <span class="hljs-keyword">if</span> word == <span class="hljs-string">&#x27;&#x27;</span>:<br>            <span class="hljs-keyword">if</span> END <span class="hljs-keyword">in</span> trie:<br>                <span class="hljs-keyword">yield</span> path<br>            <br>            <span class="hljs-keyword">if</span> edit_distance &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> trie:<br>                    <span class="hljs-keyword">if</span> k != END:<br>                        que.appendleft((trie[k], <span class="hljs-string">&#x27;&#x27;</span>, path + k, edit_distance - <span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> word[<span class="hljs-number">0</span>] <span class="hljs-keyword">in</span> trie:<br>                que.appendleft((trie[word[<span class="hljs-number">0</span>]], word[<span class="hljs-number">1</span>:], path + word[<span class="hljs-number">0</span>], edit_distance))<br>            <br>            <span class="hljs-keyword">if</span> edit_distance &gt; <span class="hljs-number">0</span>:<br>                edit_distance -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> trie.keys() - &#123;word[<span class="hljs-number">0</span>], END&#125;:<br>                    que.append((trie[k], word[<span class="hljs-number">1</span>:], path + k, edit_distance))<br>                    que.append((trie[k], word, path + k, edit_distance))<br>                <br>                que.append((trie, word[<span class="hljs-number">1</span>:], path, edit_distance))<br>                <br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(word) &gt; <span class="hljs-number">1</span>:<br>                    que.append((trie, word[<span class="hljs-number">1</span>] + word[<span class="hljs-number">0</span>] + word[<span class="hljs-number">2</span>:], path, edit_distance))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">channelModel</span>(<span class="hljs-params">x, y, edit, corpus, k=<span class="hljs-number">0.01</span></span>):<br>    corpus_str = <span class="hljs-string">&#x27; &#x27;</span>.join(corpus)<br>    corpus_len = <span class="hljs-built_in">len</span>(corpus)<br><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;add&#x27;</span>:<br>        count_xy = addmatrix.get(x + y, <span class="hljs-number">0</span>)<br>        count_y = corpus_str.count(<span class="hljs-string">&#x27; &#x27;</span> + y) <span class="hljs-keyword">if</span> x == <span class="hljs-string">&#x27;#&#x27;</span> <span class="hljs-keyword">else</span> corpus_str.count(x)<br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_y + k * corpus_len) <span class="hljs-keyword">if</span> count_y <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;sub&#x27;</span>:<br>        count_xy = submatrix.get((x + y)[:<span class="hljs-number">2</span>], <span class="hljs-number">0</span>)<br>        count_y = corpus_str.count(y)<br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_y + k * corpus_len) <span class="hljs-keyword">if</span> count_y <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;rev&#x27;</span>:<br>        count_xy = revmatrix.get(x + y, <span class="hljs-number">0</span>)<br>        count_xy_in_corpus = corpus_str.count(x + y)<br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_xy_in_corpus + k * corpus_len) <span class="hljs-keyword">if</span> count_xy_in_corpus <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-keyword">if</span> edit == <span class="hljs-string">&#x27;del&#x27;</span>:<br>        count_xy = delmatrix.get(x + y, <span class="hljs-number">0</span>)<br>        count_xy_in_corpus = corpus_str.count(x + y)<br>        <span class="hljs-keyword">return</span> (count_xy + k) / (count_xy_in_corpus + k * corpus_len) <span class="hljs-keyword">if</span> count_xy_in_corpus <span class="hljs-keyword">else</span> (count_xy + k) / corpus_len<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / corpus_len<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">spell_correct_sentence</span>(<span class="hljs-params">sentence, vocab, gram_count, corpus, V, lambdas</span>):<br>    words = word_tokenize(sentence)<br>    corrected_sentence = []<br>    <br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>        <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> vocab:<br>            corrected_sentence.append(word)<br>        <span class="hljs-keyword">else</span>:<br>            candidates = <span class="hljs-built_in">list</span>(get_candidate(trie, word, edit_distance=<span class="hljs-number">2</span>))<br>            best_candidate = word<br>            best_prob = <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>)<br>            <br>            <span class="hljs-keyword">for</span> candidate <span class="hljs-keyword">in</span> candidates:<br>                edit = editType(candidate, word)<br>                <span class="hljs-keyword">if</span> edit:<br>                    edit_prob = channelModel(edit[<span class="hljs-number">1</span>], edit[<span class="hljs-number">2</span>], edit[<span class="hljs-number">0</span>], corpus)<br>                <span class="hljs-keyword">else</span>:<br>                    edit_prob = <span class="hljs-number">1</span><br>                <br>                candidate_sentence = corrected_sentence + [candidate] + words[<span class="hljs-built_in">len</span>(corrected_sentence) + <span class="hljs-number">1</span>:]<br>                lm_prob = interpolated_language_model(gram_count, V, candidate_sentence, lambdas)<br>                total_prob = np.log(edit_prob) + lm_prob<br>                <br>                <span class="hljs-keyword">if</span> total_prob &gt; best_prob:<br>                    best_prob = total_prob<br>                    best_candidate = candidate<br>            <br>            corrected_sentence.append(best_candidate)<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join(corrected_sentence)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">correct_spelling</span>():<br>    input_sentence = input_text.get(<span class="hljs-string">&quot;1.0&quot;</span>, tk.END).strip()<br>    corrected_sentence = spell_correct_sentence(input_sentence, vocab, gram_count, corpus_text, V, (<span class="hljs-number">0.01</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.19</span>))<br>    output_text.delete(<span class="hljs-string">&quot;1.0&quot;</span>, tk.END)<br>    output_text.insert(tk.END, corrected_sentence)<br><br><span class="hljs-comment"># 创建主窗口</span><br>root = tk.Tk()<br>root.title(<span class="hljs-string">&quot;拼写纠正&quot;</span>)<br><br><span class="hljs-comment"># 创建文本输入框</span><br>input_text = tk.Text(root, height=<span class="hljs-number">10</span>, width=<span class="hljs-number">50</span>)<br>input_text.pack()<br><br><span class="hljs-comment"># 创建纠正按钮</span><br>correct_button = tk.Button(root, text=<span class="hljs-string">&quot;纠正&quot;</span>, command=correct_spelling)<br>correct_button.pack()<br><br><span class="hljs-comment"># 创建文本输出框</span><br>output_text = scrolledtext.ScrolledText(root, height=<span class="hljs-number">10</span>, width=<span class="hljs-number">50</span>)<br>output_text.pack()<br><br><span class="hljs-comment"># 运行主循环</span><br>root.mainloop()<br><br></code></pre></td></tr></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/NLP/" class="category-chain-item">NLP</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/NLP/">#NLP</a></div></div><div class="license-box my-3"><div class="license-title"><div>NLP-Spell Correction</div><div>https://furthur509.github.io/2024/10/25/NLP-Spell Correction/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Yang Mingxin</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年10月25日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2024/10/25/HUST%20SE%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AE%9E%E9%AA%8C%E6%96%87%E6%A1%A3/" title="HUST-SE软件体系结构实验文档"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">HUST-SE软件体系结构实验文档</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2024/10/24/MarsCode-%E8%B4%AA%E5%BF%83%E7%9A%84%E5%B0%8F%E5%8C%85/" title="MarsCode-贪心的小包"><span class="hidden-mobile">MarsCode-贪心的小包</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>